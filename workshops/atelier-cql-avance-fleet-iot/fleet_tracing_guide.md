# Fleet Tracing IoT - Guide de Mise en Å’uvre Complet

## ğŸ“‹ RÃ©sumÃ© ExÃ©cutif

Ce projet demande l'implÃ©mentation d'une plateforme complÃ¨te de suivi de flotte avec trois composants majeurs :
- **Volet 1** : Pipeline ETL (Python) pour l'ingestion et transformation des donnÃ©es
- **Volet 2** : Cluster Cassandra Multi-Datacenter pour le stockage rÃ©silient
- **Volet 3** : Dashboard interactif pour la visualisation et l'analyse

**DurÃ©e estimÃ©e** : 1 jour (7 heures)  
**Ressources requises** : Docker, Python 3.11+, Cassandra 4.1+

---

## ğŸ—ï¸ Phase 1 : Configuration de l'Environnement (1-2 jours)

### 1.1 Structure du Projet

```bash
fleet-tracing-project/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â”œâ”€â”€ RAPPORT.md
â”‚
â”œâ”€â”€ cassandra/
â”‚   â”œâ”€â”€ init-scripts/
â”‚   â”‚   â””â”€â”€ 01-create-schema.cql
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ cassandra.yaml (optionnel)
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ etl_pipeline.py
â”‚   â”œâ”€â”€ data_generator.py
â”‚   â”œâ”€â”€ cassandra_writer.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ test_etl.py
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ realtime.py
â”‚   â”‚   â”œâ”€â”€ analytics.py
â”‚   â”‚   â””â”€â”€ alerts.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ cassandra_client.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_telemetry.csv
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ architecture.md
    â”œâ”€â”€ cassandra-modeling.md
    â””â”€â”€ user-guide.md
```

### 1.2 PrÃ©paration de docker-compose.yml

Points clÃ©s Ã  respecter :
- Configuration des 4 nÅ“uds Cassandra (DC1: 2 nÅ“uds, DC2: 2 nÅ“uds)
- Seed nodes pour la dÃ©couverte inter-DC
- Health checks robustes
- DÃ©pendances entre services (Cassandra â†’ ETL â†’ Dashboard)
- Network bridge isolÃ© pour la communication intra-cluster

### 1.3 Script d'Initialisation Cassandra

Le fichier `01-create-schema.cql` doit crÃ©er :

**Keyspace** :
```sql
CREATE KEYSPACE fleet_iot
WITH REPLICATION = {
  'class': 'NetworkTopologyStrategy',
  'dc1': 2,
  'dc2': 2
}
AND durable_writes = true;
```

**Cinq tables essentielles** :

1. **devices_by_fleet** : Listing des vÃ©hicules par flotte
   - PK: `(fleet_id)`, CC: `device_id`
   - RequÃªte : Lister tous les vÃ©hicules d'une flotte

2. **latest_telemetry_by_device** : Dernier Ã©tat connu
   - PK: `device_id`
   - RequÃªte : Position/Ã©tat actuels pour le dashboard live

3. **telemetry_by_device_day** : Historique journalier
   - PK: `(device_id, day)`, CC: `ts DESC`
   - TTL: 30 jours
   - RequÃªte : Trajet d'un jour avec bucketing temporal

4. **alerts_by_fleet_day** : Alertes structurÃ©es
   - PK: `(fleet_id, day, severity)`, CC: `ts DESC, device_id`
   - RequÃªte : Filtrer par sÃ©vÃ©ritÃ© et date

5. **fleet_analytics_by_day** : AgrÃ©gations prÃ©calculÃ©es
   - PK: `(fleet_id, day)`, CC: `hour`
   - RequÃªte : Stats horaires d'une flotte

### 1.4 VÃ©rification du Cluster

```bash
# DÃ©marrer le cluster
docker compose up -d

# Attendre la convergence (5-10 min)
docker compose logs cassandra-dc1-node1

# VÃ©rifier le statut
docker exec -it cassandra-dc1-node1 nodetool status

# RÃ©sultat attendu : UN (Up/Normal) pour les 4 nÅ“uds
# Datacenter: dc1 (2 nÅ“uds - 50% chacun)
# Datacenter: dc2 (2 nÅ“uds - 50% chacun)
```

**Checkpoint âœ…** : Tous les services marquÃ©s "healthy"

---

## ğŸ”„ Phase 2 : Pipeline ETL (2-3 H)

### 2.1 Configuration (config.py)

```python
# Variables d'environnement
CASSANDRA_HOSTS = os.getenv('CASSANDRA_HOSTS', 'localhost').split(',')
CASSANDRA_KEYSPACE = os.getenv('CASSANDRA_KEYSPACE', 'fleet_iot')
CASSANDRA_DC = os.getenv('CASSANDRA_DC', 'dc1')

# ParamÃ¨tres de performance
BATCH_SIZE = 100
ASYNC_CONCURRENCY = 50  # RequÃªtes async en parallÃ¨le
WRITE_TIMEOUT = 30  # secondes

# Monitoring
METRICS_INTERVAL = 60  # Afficher les stats tous les 60s
```

### 2.2 Writer Cassandra (cassandra_writer.py)

Points critiques Ã  implÃ©menter :

**1. Connexion MDC**
```python
from cassandra.cluster import Cluster, ExecutionProfile
from cassandra.policies import DCAwareRoundRobinPolicy, TokenAwarePolicy

profile = ExecutionProfile(
    load_balancing_policy=TokenAwarePolicy(
        DCAwareRoundRobinPolicy(local_dc='dc1')
    )
)
cluster = Cluster(contact_points, execution_profiles={'default': profile})
```

**2. Prepared Statements** (impÃ©ratif pour la performance)
```python
self.insert_latest = session.prepare("""
    INSERT INTO latest_telemetry_by_device 
    (device_id, last_ts, lat, lon, speed_kmh, battery_pct, temp_c)
    VALUES (?, ?, ?, ?, ?, ?, ?)
""")
```

**3. Modes d'insertion**

- **Batch** : Pour les insertions groupÃ©es (historique)
  - Avantage : Une seule requÃªte pour N records
  - Risque : Taille max 65K (limitation Cassandra)
  
- **Asynchrone** : Pour les flux temps rÃ©el
  - Avantage : Non-bloquant, throughput maximal
  - ImplÃ©mentation : `session.execute_async()` + gestion des futures

**4. Gestion d'erreurs et retry**
```python
try:
    future = session.execute_async(stmt, params)
    future.result(timeout=30)
except WriteTimeout:
    # Retry avec backoff exponentiel
except InvalidRequest:
    # Erreur de schÃ©ma - Ã  logger et ignorer
```

### 2.3 GÃ©nÃ©rateur de DonnÃ©es (data_generator.py)

**DonnÃ©es rÃ©alistes** :
- GPS : CoordonnÃ©es centrÃ©es sur une zone (ex: Ãle-de-France)
- Vitesse : 0-130 km/h (distribution rÃ©aliste selon heure)
- Batterie : 20-100% (dÃ©gradation linÃ©aire dans la journÃ©e)
- TempÃ©rature : 15-35Â°C (variation saisonniÃ¨re)
- Zone : Classification discrÃ¨te (zone_a, zone_b, zone_c)

**Temporal coherence** :
```python
# GÃ©nÃ©rer des sÃ©ries cohÃ©rentes (pas de sauts temporels abruptes)
for device in devices:
    timestamp = base_time
    for i in range(num_points):
        record = {
            'device_id': device,
            'timestamp': timestamp,
            'lat': previous_lat + random.gauss(0, 0.001),  # Petit dÃ©placement
            'speed_kmh': random.uniform(previous_speed - 5, previous_speed + 5),
            ...
        }
        previous_lat = record['lat']
        previous_speed = record['speed_kmh']
        timestamp -= timedelta(seconds=30)
```

### 2.4 Pipeline Principal (etl_pipeline.py)

**Deux modes d'exÃ©cution** :

**Mode 1 : Batch (Historique)**
```
Objectif : Charger 50k+ records rapidement
StratÃ©gie :
  - GÃ©nÃ©rer 50 batches de 1000 records
  - Chaque batch = 1 sec (rate limiting)
  - DurÃ©e totale : 50-60 secondes
  - Mesurer : latence P50/P95, throughput
```

**Mode 2 : Streaming (Temps rÃ©el)**
```
Objectif : Simuler un flux continu
StratÃ©gie :
  - GÃ©nÃ©rer 10 records/itÃ©ration (1 par device)
  - DÃ©lai inter-itÃ©ration : 5 secondes
  - Asynchrone : Ne pas bloquer sur write
  - DurÃ©e : 10 minutes (test)
```

### 2.5 Monitoring et MÃ©triques

Ã€ implÃ©menter dans l'ETL :

```python
class ETLMetrics:
    def __init__(self):
        self.records_written = 0
        self.errors = 0
        self.start_time = time.time()
    
    def update(self, num_records, duration):
        throughput = num_records / duration  # records/sec
        avg_latency = duration / num_records * 1000  # ms
        
    def report(self):
        elapsed = time.time() - self.start_time
        throughput = self.records_written / elapsed
        print(f"Throughput: {throughput:.0f} rec/s | Errors: {self.errors}")
```

### 2.6 Tests de Charge

Benchmarks attendus :

| Mode | Taille | DurÃ©e | Throughput | Latence P99 |
|------|--------|-------|-----------|------------|
| Batch | 100 records | 1-2s | 50-100 rec/s | <100ms |
| Streaming | 100 records | 10-20s | 5-10 rec/s | <200ms |

**Test de rÃ©silience** :
```bash
# Pendant le chargement ETL :
docker stop cassandra-dc1-node2

# L'ETL doit continuer (replication_factor=2)
# Puis redÃ©marrer le nÅ“ud
docker start cassandra-dc1-node2
nodetool repair
```

**Livrables** :
- âœ… Code ETL complet et fonctionnel
- âœ… 50k+ records insÃ©rÃ©s avec logs
- âœ… Rapport: latence P50/P95/P99, throughput, overhead

---

## ğŸ“Š Phase 3 : Dashboard (2-3 H)

### 3.1 Client Cassandra (utils/cassandra_client.py)

**MÃ©thodes essentielles** :

```python
def get_latest_telemetry(device_id):
    # O(1) - Partition key lookup
    # Retourne : position, vitesse, batterie, temp actuels

def get_device_history(device_id, day, limit=500):
    # O(log N) - Range query sur timestamp
    # Retourne : DataFrame avec tous les points du jour

def get_fleet_latest_all(fleet_id):
    # Listera d'abord les devices (devices_by_fleet)
    # Puis requÃªte get_latest_telemetry pour chacun
    # âš ï¸ N requÃªtes â†’ optimiser avec cache

def get_fleet_alerts(fleet_id, day, severity=None):
    # RÃ©cupÃ¨re alertes filtrÃ©es par sÃ©vÃ©ritÃ©
    # Si severity=ALL â†’ requÃªte 3 severities diffÃ©rentes

def get_fleet_analytics(fleet_id, day):
    # Stats agrÃ©gÃ©es par heure
```

**Optimisations** :

1. **Caching** (optionnel mais recommandÃ©)
```python
from functools import lru_cache
import time

@lru_cache(maxsize=128)
def get_latest_cached(device_id):
    result = get_latest_telemetry(device_id)
    # Invalider aprÃ¨s 30 secondes
    return result
```

2. **Pagination pour gros volumes**
```python
def get_device_history_paginated(device_id, day, page_size=100):
    query = """
        SELECT * FROM telemetry_by_device_day
        WHERE device_id = %s AND day = %s
        LIMIT %s
    """
    # Utiliser paging_state pour pagination
```

3. **RequÃªtes optimisÃ©es**
```python
# âŒ Anti-pattern : SELECT * suivi de filtrage en Python
results = session.execute("SELECT * FROM ...")
filtered = [r for r in results if r.speed > 50]

# âœ… Correct : Filtrage cÃ´tÃ© requÃªte
results = session.execute("""
    SELECT * FROM telemetry_by_device_day
    WHERE device_id = %s AND day = %s AND ts > ?
""")
```

### 3.2 Page Real-Time (pages/realtime.py)

**Composants** :

1. **SÃ©lection flotte (Sidebar)**
   - Input text pour fleet_id
   - SÃ©lecteur de date

2. **MÃ©triques KPI (haut)**
   ```python
   col1, col2, col3, col4 = st.columns(4)
   col1.metric("Active Devices", 47)
   col2.metric("Avg Speed", "42 km/h")
   col3.metric("Avg Battery", "78%")
   col4.metric("Critical Alerts", 2)
   ```

3. **Carte interactive (centre)**
   ```python
   import plotly.express as px
   fig = px.scatter_mapbox(
       devices_df,
       lat='lat', lon='lon',
       hover_name='device_id',
       color='speed_kmh',  # Colorer par vitesse
       zoom=10,
       mapbox_style="open-street-map"
   )
   st.plotly_chart(fig, use_container_width=True)
   ```

4. **Tableau des devices (bas)**
   - Colonnes : device_id, position, vitesse, batterie, tempÃ©rature
   - Tri/filtrage activÃ©s

### 3.3 Page Analytics (pages/analytics.py)

**Graphiques temporels** :

1. **Vitesse dans le temps**
   ```python
   fig = px.line(
       history_df, x='ts', y='speed_kmh',
       title='Speed Evolution',
       range_y=[0, 150]
   )
   ```

2. **Batterie dans le temps**
   ```python
   fig = px.line(
       history_df, x='ts', y='battery_pct',
       title='Battery Level'
   )
   ```

3. **TempÃ©rature et humiditÃ©**
   ```python
   fig = px.scatter(
       history_df, x='ts', y='temp_c',
       title='Temperature Trend'
   )
   ```

**Comparaisons** :

```python
# Comparer N devices sur mÃªme mÃ©trique
multi_device_data = pd.concat([
    get_device_history(d, selected_date)
    for d in selected_devices
])

fig = px.line(
    multi_device_data, x='ts', y='speed_kmh',
    color='device_id',
    title='Multi-Device Comparison'
)
```

### 3.4 Page Alerts (pages/alerts.py)

**Filtres** :
- SÃ©vÃ©ritÃ© (HIGH, MEDIUM, LOW, ALL)
- Plage de dates
- Type d'alerte

**Visualisations** :

1. **Compteurs par sÃ©vÃ©ritÃ©**
   ```python
   alerts_df['severity'].value_counts()
   # Afficher en KPI
   ```

2. **Timeline visuelle**
   ```python
   fig = px.scatter(
       alerts_df,
       x='ts', y='device_id',
       color='severity',
       color_discrete_map={'HIGH': 'red', 'MEDIUM': 'orange', 'LOW': 'yellow'},
       size='severity',
       title='Alerts Timeline'
   )
   ```

3. **Table des alertes**
   - ColonnÃ© cliquable pour dÃ©tails
   - Lien vers le device concernÃ©

### 3.5 Livrables Dashboard

- âœ… App Streamlit dÃ©marrÃ©e sur http://localhost:8501
- âœ… 3 pages fonctionnelles
- âœ… RequÃªtes CQL documentÃ©es
- âœ… Captures d'Ã©cran des pages

---

## ğŸ” Phase 4 : Optimisations & RÃ©silience (1-2 H)

### 4.1 Tuning de Performance

**Identifier les slow queries** :

```python
# Activer le tracing
stmt = SimpleStatement(query)
stmt.trace = True
result = session.execute(stmt)
print(result.trace)

# Lire le tracing
for event in result.trace.events:
    print(f"{event.description}")
```

**ProblÃ¨mes communs et solutions** :

| ProblÃ¨me | Cause | Solution |
|----------|-------|----------|
| Latence Ã©levÃ©e sur `get_latest_all()` | N requÃªtes sÃ©quentielles | Ajouter cache ou parallel requests |
| RequÃªte sur colonne non-clÃ© | Full scan | Ajouter index secondaire (sparingly) |
| Memory OOM sur gros range | Pagination absente | ImplÃ©menter `fetch_size()` |

### 4.2 Tests de RÃ©silience

**ScÃ©nario 1 : Perte d'un nÅ“ud**

```bash
# Phase 1 : Chargement en cours
docker compose up etl-pipeline

# Phase 2 : Kill un nÅ“ud pendant le chargement
docker stop cassandra-dc1-node2

# Phase 3 : VÃ©rifier que
#  - ETL continue (quorum toujours atteint)
#  - Dashboard reste accessible
#  - Pas de perte de donnÃ©es (RF=2)

# Phase 4 : RedÃ©marrer et rÃ©parer
docker start cassandra-dc1-node2
docker exec cassandra-dc1-node2 nodetool repair
```

**ScÃ©nario 2 : Perte d'un datacenter**

```bash
# ArrÃªter tous les nÅ“uds dc2
docker stop cassandra-dc2-node1 cassandra-dc2-node2

# VÃ©rifier que le systÃ¨me continue
# DonnÃ©es disponibles avec RF=2 en dc1

# RedÃ©marrer
docker start cassandra-dc2-node1 cassandra-dc2-node2
```

### 4.3 Documentation Technique

**Ã€ inclure dans RAPPORT.pdf** :

1. **Architecture dÃ©cisionnelle**
   - Diagramme : DataSources â†’ ETL â†’ Cassandra â†’ Dashboard
   - Justification de chaque table
   - StratÃ©gie de partitionnement

2. **ModÃ©lisation NoSQL**
   - Query-first design : pour chaque requÃªte â†’ table appropriÃ©e
   - Denormalization : rÃ©pÃ©tition dÃ©libÃ©rÃ©e (normal en NoSQL)
   - Clustering strategy : tri des donnÃ©es

3. **RÃ©silience**
   - Replica factor : 2 par DC (4 copies totales)
   - Quorum reads/writes : garantit cohÃ©rence
   - Tests de failover documentÃ©s

4. **Performance**
   - Benchmarks : throughput (rec/s), latence (ms)
   - Comparaison batch vs async
   - Impact du cache

5. **Captures d'Ã©cran**
   - Real-time page avec 10+ devices
   - Analytics page avec graphiques temporels
   - Alerts page avec timeline

---

## ğŸ“¦ Rendu Final

### Structure du Livrable

```
fleet-tracing-project.zip
â”œâ”€â”€ README.md (instructions dÃ©ploiement)
â”œâ”€â”€ RAPPORT.pdf (5-10 pages)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”‚
â”œâ”€â”€ cassandra/
â”‚   â””â”€â”€ init-scripts/01-create-schema.cql
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ etl_pipeline.py
â”‚   â”œâ”€â”€ cassandra_writer.py
â”‚   â”œâ”€â”€ data_generator.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ tests/test_etl.py
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ pages/ (realtime.py, analytics.py, alerts.py)
â”‚   â””â”€â”€ utils/cassandra_client.py
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ cassandra-modeling.md
â”‚   â””â”€â”€ user-guide.md
â”‚
â””â”€â”€ screenshots/
    â”œâ”€â”€ realtime-page.png
    â”œâ”€â”€ analytics-page.png
    â””â”€â”€ alerts-page.png
```

### Contenu du RAPPORT.pdf

1. **Page de couverture** : Titre, auteur, date
2. **Executive Summary** : 1 page avec rÃ©sumÃ© et rÃ©sultats clÃ©s
3. **Architecture Technique** : 2 pages avec diagrammes
4. **ModÃ©lisation de DonnÃ©es** : 2 pages (justification des tables)
5. **Performance & RÃ©silience** : 2 pages (benchmarks, tests failover)
6. **Guide d'Utilisation** : 1 page (dÃ©marrer le systÃ¨me)
7. **Annexes** : Screenshots, logs de test

### Commandes de DÃ©ploiement

```bash
# 1. Initialiser
git clone <repo>
cd fleet-tracing-project
cp .env.example .env

# 2. DÃ©marrer
docker compose up -d

# 3. VÃ©rifier
docker compose logs cassandra-dc1-node1
docker exec cassandra-dc1-node1 nodetool status

# 4. AccÃ©der au dashboard
# http://localhost:8501

# 5. ArrÃªter
docker compose down
```

### Checklist de Validation

- [ ] Tous les 4 nÅ“uds Cassandra "UP/Normal"
- [ ] 50k+ records chargÃ©s en ETL (logs visibles)
- [ ] Dashboard accessible et affichant des donnÃ©es
- [ ] Real-Time page avec carte et KPI
- [ ] Analytics page avec graphiques temporels
- [ ] Alerts page avec filtres
- [ ] Test failover rÃ©ussi (stop/start nÅ“ud)
- [ ] RAPPORT.pdf complÃ©tÃ©
- [ ] README.md avec instructions claires

---

 

## ğŸ’¡ Conseils ClÃ©s

1. **Commencer simple** : Faire fonctionner le cluster avant d'ajouter la complexitÃ©
2. **Tester frÃ©quemment** : VÃ©rifier Ã  chaque Ã©tape que les donnÃ©es circulent
3. **Documenter en cours** : Prendre des screenshots au fur et Ã  mesure
4. **Automatiser les tests** : Scripts bash pour vÃ©rifier la convergence du cluster
5. **Git** : Commiter rÃ©guliÃ¨rement (une commit par livrable)

---

## ğŸ”— Ressources Essentielles

- [Cassandra Data Modeling](https://cassandra.apache.org/doc/latest/developing/cql/)
- [Python Driver API](https://docs.datastax.com/en/developer/python-driver/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Docker Compose Reference](https://docs.docker.com/compose/compose-file/)
